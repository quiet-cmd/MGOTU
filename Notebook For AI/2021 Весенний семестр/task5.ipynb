{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зависимости\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем все известные генераторы случаынйх чисел / Setting all known random seeds\n",
    "my_code = \"Johnson\"\n",
    "seed_limit = 2 ** 32\n",
    "my_seed = int.from_bytes(my_code.encode(), \"little\") % seed_limit\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(my_seed)\n",
    "\n",
    "random.seed(my_seed)\n",
    "\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "tf.compat.v1.set_random_seed(my_seed)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем данные из файла\n",
    "example_data = pd.read_csv(\"datasets/Fish.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим размер валидационной и тестовой выборок\n",
    "val_test_size = round(0.2*len(example_data))\n",
    "print(val_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим обучающую, валидационную и тестовую выборки\n",
    "random_state = my_seed\n",
    "train_val, test = train_test_split(example_data, test_size=val_test_size, random_state=random_state)\n",
    "train, val = train_test_split(train_val, test_size=val_test_size, random_state=random_state)\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Значения в числовых столбцах преобразуем к отрезку [0,1].\n",
    "# Для настройки скалировщика используем только обучающую выборку.\n",
    "num_columns = ['Weight', 'Length1', 'Length2', 'Length3', 'Height', 'Width']\n",
    "ord_columns = ['Species']\n",
    "\n",
    "ct = ColumnTransformer(transformers=[\n",
    "    ('numerical', MinMaxScaler(), num_columns), \n",
    "    ('ordinal', OneHotEncoder(), ord_columns)])\n",
    "\n",
    "ct.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем значения, тип данных приводим к DataFrame\n",
    "sc_train = pd.DataFrame(ct.transform(train))\n",
    "sc_test = pd.DataFrame(ct.transform(test))\n",
    "sc_val = pd.DataFrame(ct.transform(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем названия столбцов\n",
    "column_names = num_columns + list(range(7))\n",
    "sc_train.columns = column_names\n",
    "sc_test.columns = column_names\n",
    "sc_val.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В качестве входных параметров используем первые 5 числовых параметров,\n",
    "# в качестве выходного - шестой числовой параметр.\n",
    "x_labels = num_columns[:-1]\n",
    "y_labels = num_columns[-1]\n",
    "print(x_labels)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отберем необходимые параметры\n",
    "x_train = sc_train[x_labels]\n",
    "x_test = sc_test[x_labels]\n",
    "x_val = sc_val[x_labels]\n",
    "\n",
    "y_train = sc_train[y_labels]\n",
    "y_test = sc_test[y_labels]\n",
    "y_val = sc_val[y_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим нейроннную сеть для решения задачи регрессии на базе библиотеки sklearn\n",
    "reg = MLPRegressor(alpha=0.0, batch_size=16, epsilon=1e-07, max_iter=50)\n",
    "reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Обучим нейронную сеть\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Проверим работу обученной нейронной сети на валидационной выборке\n",
    "pred_val = reg.predict(x_val)\n",
    "mse1 = mean_squared_error(y_val, pred_val)\n",
    "print(mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим нейронную сеть на базе библиотеки keras\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, input_dim=5, activation='relu', use_bias=False))\n",
    "\n",
    "model.add(Dense(1, activation='linear', use_bias=False))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим нейронную сеть\n",
    "history = model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs=50, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим работу обученной нейронной сети на валидационной выборке\n",
    "pred_val2 = model.predict(x_val)\n",
    "mse2 = mean_squared_error(y_val, pred_val2)\n",
    "print(mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Создаем нейронную сеть со слоем дропаута\n",
    "drop = Sequential()\n",
    "\n",
    "drop.add(Dense(100, input_dim=5, activation='relu', use_bias=False))\n",
    "\n",
    "drop.add(Dropout(rate=0.5))\n",
    "\n",
    "drop.add(Dense(1, activation='linear', use_bias=False))\n",
    "\n",
    "drop.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим нейронную сеть\n",
    "history = drop.fit(x_train, y_train, validation_data = (x_val, y_val), epochs=50, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим работу обученной нейронной сети на валидационной выборке\n",
    "pred_val3 = drop.predict(x_val)\n",
    "mse3 = mean_squared_error(y_val, pred_val3)\n",
    "print(mse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mse1, mse2, mse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем на тестовой выборке\n",
    "pred_test = model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, pred_test)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание №1 - решение задачи классификации.\n",
    "# В качестве входных параметров используем все числовые параметры,\n",
    "# в качестве выходного - единственный категориальный параметр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = num_columns\n",
    "y_labels = list(range(7))\n",
    "print(x_labels)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Отберем необходимые параметры\n",
    "x_train = sc_train[x_labels]\n",
    "x_test = sc_test[x_labels]\n",
    "x_val = sc_val[x_labels]\n",
    "\n",
    "y_train = sc_train[y_labels]\n",
    "y_test = sc_test[y_labels]\n",
    "y_val = sc_val[y_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте нейронную сеть для решения задачи классификации двумя способами: с помощью sklearn и keras.\n",
    "# Сравните их эффективность.\n",
    "# Для keras используйте loss и metrics = 'categorical_crossentropy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание №2 - использование dropout-слоя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте нейронную сеть для решения задачи классификации с помощью keras. Используйте dropout-слой.\n",
    "# Сравните эффективность нейронных сетей с dropout-слоем и без него.\n",
    "# Попробуйте найти такие параметры dropout-слоя, чтобы сеть с ним работала лучше, чем без него."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
