{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn as sk\n\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Набор данных взят с https://www.kaggle.com/aungpyaeap/fish-market\n# Параметры нескольких популярных промысловых рыб\n# length 1 = Body height\n# length 2 = Total Length\n# length 3 = Diagonal Length\nfish_data = pd.read_csv(\"datasets/Fish.csv\", delimiter=',')\nprint(fish_data)","execution_count":2,"outputs":[{"output_type":"stream","text":"    Species  Weight  Length1  Length2  Length3   Height   Width\n0     Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n1     Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n2     Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n3     Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n4     Bream   430.0     26.5     29.0     34.0  12.4440  5.1340\n..      ...     ...      ...      ...      ...      ...     ...\n154   Smelt    12.2     11.5     12.2     13.4   2.0904  1.3936\n155   Smelt    13.4     11.7     12.4     13.5   2.4300  1.2690\n156   Smelt    12.2     12.1     13.0     13.8   2.2770  1.2558\n157   Smelt    19.7     13.2     14.3     15.2   2.8728  2.0672\n158   Smelt    19.9     13.8     15.0     16.2   2.9322  1.8792\n\n[159 rows x 7 columns]\n","name":"stdout"}]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Выделим две переменных\nx_label = ['Length1','Length2','Length3','Height','Width']\ny_label = 'Weight'\ndata = fish_data[[*x_label, y_label]]\nprint(data)","execution_count":3,"outputs":[{"output_type":"stream","text":"     Length1  Length2  Length3   Height   Width  Weight\n0       23.2     25.4     30.0  11.5200  4.0200   242.0\n1       24.0     26.3     31.2  12.4800  4.3056   290.0\n2       23.9     26.5     31.1  12.3778  4.6961   340.0\n3       26.3     29.0     33.5  12.7300  4.4555   363.0\n4       26.5     29.0     34.0  12.4440  5.1340   430.0\n..       ...      ...      ...      ...     ...     ...\n154     11.5     12.2     13.4   2.0904  1.3936    12.2\n155     11.7     12.4     13.5   2.4300  1.2690    13.4\n156     12.1     13.0     13.8   2.2770  1.2558    12.2\n157     13.2     14.3     15.2   2.8728  2.0672    19.7\n158     13.8     15.0     16.2   2.9322  1.8792    19.9\n\n[159 rows x 6 columns]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определим размер валидационной и тестовой выборок\nval_test_size = round(0.2*len(data))\nprint(val_test_size)","execution_count":4,"outputs":[{"output_type":"stream","text":"32\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Генерируем уникальный seed\nmy_code = \"Петров\"\nseed_limit = 2 ** 32\nmy_seed = int.from_bytes(my_code.encode(), \"little\") % seed_limit","execution_count":5,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Создадим обучающую, валидационную и тестовую выборки\nrandom_state = my_seed\ntrain_val, test = train_test_split(data, test_size=val_test_size, random_state=random_state)\ntrain, val = train_test_split(train_val, test_size=val_test_size, random_state=random_state)\nprint(len(train), len(val), len(test))","execution_count":6,"outputs":[{"output_type":"stream","text":"95 32 32\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразуем данные к ожидаемому библиотекой skleran формату\ntrain_x = np.array(train[x_label])\ntrain_y = np.array(train[y_label]).reshape(-1,1)\n\nval_x = np.array(val[x_label])\nval_y = np.array(val[y_label]).reshape(-1,1)\n\ntest_x = np.array(test[x_label])\ntest_y = np.array(test[y_label]).reshape(-1,1)","execution_count":7,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Результат не очень хорош для интерпретации, попробуем сначала нормировать значения\nscaler_x = MinMaxScaler().fit(train_x)\nscaled_train_x = scaler_x.transform(train_x)\n\nscaler_y = MinMaxScaler().fit(train_y)\nscaled_train_y = scaler_y.transform(train_y)","execution_count":8,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Строим модель и выводим результаты для нормированных данных\nmodel1 = linear_model.LinearRegression()\nmodel1.fit(scaled_train_x, scaled_train_y)\n\ny = 0\nfor i in range(len(x_label)):\n    y += model1.coef_[0][i] * np.linspace(min(scaled_train_x[i]), max(scaled_train_x[i]), 100)\ny += model1.intercept_","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверим результат на валидационной выборке\nscaled_val_x = scaler_x.transform(val_x)\nscaled_val_y = scaler_y.transform(val_y)\n\nval_predicted = model1.predict(scaled_val_x)\n\nmse1 = mean_squared_error(scaled_val_y, val_predicted)\nprint(mse1)","execution_count":10,"outputs":[{"output_type":"stream","text":"0.0031136070853906087\n","name":"stdout"}]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Построим модель линейной регресси с L1-регуляризацией и выведем результаты для нормированных данных.\nmodel2 = linear_model.Lasso(alpha=0.01)\nmodel2.fit(scaled_train_x, scaled_train_y)\n\ny = 0\nfor i in range(len(x_label)):\n    y += model1.coef_[0][i] * np.linspace(min(scaled_train_x[i]), max(scaled_train_x[i]), 100)\ny += model2.intercept_","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверим результат на валидационной выборке\nscaled_val_x = scaler_x.transform(val_x)\nscaled_val_y = scaler_y.transform(val_y)\n\nval_predicted = model2.predict(scaled_val_x)\n\nmse2 = mean_squared_error(scaled_val_y, val_predicted)\nprint(mse2)\n# Можете поэкспериментировать со значением параметра alpha, чтобы уменьшить ошибку","execution_count":12,"outputs":[{"output_type":"stream","text":"0.00549300341645257\n","name":"stdout"}]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Построим модель линейной регресси с L2-регуляризацией и выведем результаты для нормированных данных\nmodel3 = linear_model.Ridge(alpha=0.01)\nmodel3.fit(scaled_train_x, scaled_train_y)\n\ny = 0\nfor i in range(len(x_label)):\n    y += model1.coef_[0][i] * np.linspace(min(scaled_train_x[i]), max(scaled_train_x[i]), 100)\ny += model3.intercept_","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверим результат на валидационной выборке\nscaled_val_x = scaler_x.transform(val_x)\nscaled_val_y = scaler_y.transform(val_y)\n\nval_predicted = model3.predict(scaled_val_x)\n\nmse3 = mean_squared_error(scaled_val_y, val_predicted)\nprint(mse3)\n# Можете поэкспериментировать со значением параметра alpha, чтобы уменьшить ошибку","execution_count":14,"outputs":[{"output_type":"stream","text":"0.0031389220862907286\n","name":"stdout"}]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Построим модель линейной регресси с ElasticNet-регуляризацией и выведем результаты для нормированных данных\nmodel4 = linear_model.ElasticNet(alpha=0.01, l1_ratio = 0.01)\nmodel4.fit(scaled_train_x, scaled_train_y)\n\ny = 0\nfor i in range(len(x_label)):\n    y += model1.coef_[0][i] * np.linspace(min(scaled_train_x[i]), max(scaled_train_x[i]), 100)\ny += model4.intercept_","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверим результат на валидационной выборке\nscaled_val_x = scaler_x.transform(val_x)\nscaled_val_y = scaler_y.transform(val_y)\n\nval_predicted = model4.predict(scaled_val_x)\n\nmse4 = mean_squared_error(scaled_val_y, val_predicted)\nprint(mse4)\n# Можете поэкспериментировать со значениями параметров alpha и l1_ratio, чтобы уменьшить ошибку","execution_count":16,"outputs":[{"output_type":"stream","text":"0.003336236794176126\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выведем ошибки для моделей на нормированных данных\nprint(mse1, mse2, mse3, mse4)","execution_count":17,"outputs":[{"output_type":"stream","text":"0.0031136070853906087 0.00549300341645257 0.0031389220862907286 0.003336236794176126\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Минимальное значение достигается для второй модели, получим итоговую величину ошибки на тестовой выборке\nscaled_test_x = scaler_x.transform(test_x)\nscaled_test_y = scaler_y.transform(test_y)\n\ntest_predicted = model2.predict(scaled_test_x)\n\nmse_test = mean_squared_error(scaled_test_y, test_predicted)\nprint(mse_test)","execution_count":18,"outputs":[{"output_type":"stream","text":"0.005834808949279808\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}